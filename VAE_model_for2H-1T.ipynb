{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from loaddata import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data1=readtraining_data(\"inter_a_b/train_XX.p\",\"inter_a_b/train_YY.npy\",\"inter_a_b/train_pos.npy\")\n",
    "train_data2=readtraining_data(\"inter_a_b/sur_XX.p\",\"inter_a_b/sur_YY.npy\",\"inter_a_b/sur_pos.npy\")\n",
    "train_data=mergedata(train_data1,train_data2)\n",
    "train_data.print_info()\n",
    "output_class = 4\n",
    "print(train_data.labels.shape)\n",
    "#create training data\n",
    "stats,min_frac=count_stats(output_class,train_data.labels,train_data.elements)\n",
    "min_frac=0.99*min_frac\n",
    "train_data_1=select_data(train_data,min_frac,stats)\n",
    "print(\"====New Data====\")\n",
    "train_data=train_data_1\n",
    "train_data.print_info()\n",
    "num_training = train_data.elements\n",
    "count_stats(output_class,train_data.labels,train_data.elements)\n",
    "print(\"max value:\",np.max(train_data.feature_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ii=np.argwhere(train_data.labels==2)\n",
    "viz_val=ii[15][0]\n",
    "fig, (ax0, ax1,ax2,ax3) = plt.subplots(ncols=4,figsize=(16, 8))\n",
    "ax0.imshow(train_data.feature_vec[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(train_data.feature_vec[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(train_data.feature_vec[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "tt=(train_data.feature_vec[viz_val,:,:,0]/2.0)+(train_data.feature_vec[viz_val,:,:,1]*1.0)\\\n",
    "+(train_data.feature_vec[viz_val,:,:,2]/2.0)\n",
    "ax3.imshow(tt,cmap=plt.cm.cool)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defination of all the kernels\n",
    "def conv2d(input, kernel_size, stride, num_filter, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding = 'SAME') + b\n",
    "    \n",
    "def conv2d_transpose(input, kernel_size, stride, num_filter, name = 'conv2d_transpose'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "        output_shape = tf.stack([tf.shape(input)[0], tf.shape(input)[1] * 2, tf.shape(input)[2] * 2, num_filter])\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W, output_shape, stride_shape, padding = 'SAME') + b\n",
    "    \n",
    "def fc(input, num_output, name = 'fc'):\n",
    "    with tf.variable_scope(name):\n",
    "        num_input = input.get_shape()[1]\n",
    "        W = tf.get_variable('w', [num_input, num_output], tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [num_output], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input, W) + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "    \n",
    "def dropout(input,keep_prob,is_train):\n",
    "    return tf.layers.dropout(input,keep_prob,training=is_train)\n",
    "\n",
    "def batch_norm(input, is_training):\n",
    "    out = tf.contrib.layers.batch_norm(input, decay = 0.99, center = True, scale = True,\n",
    "                                       is_training = is_training, updates_collections = None)\n",
    "    return out\n",
    "\n",
    "def leaky_relu(input, alpha = 0.2):\n",
    "    return tf.maximum(alpha * input, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 150\n",
    "        self.input_w = 64\n",
    "        self.batch_size = 64\n",
    "        self.log_step = 50\n",
    "        self.learning_rate = 1e-3\n",
    "        self.n_latent = 20\n",
    "        self.is_train  = tf.placeholder(tf.bool)\n",
    "        self.keep_prob = 0.50\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.input_w, self.input_w, 3])\n",
    "        self.X_flat = tf.reshape(self.X, shape=[-1, self.input_w * self.input_w * 3])\n",
    "        print(str(self.X.get_shape()))\n",
    "        self._build_model()\n",
    "        #self.sess = tf.InteractiveSession()\n",
    "        #self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def encoder(self,input):\n",
    "         with tf.variable_scope(\"encoder\", reuse=None):\n",
    "                en_conv1 =  conv2d(input, 4, 2, 32, 'conv1')\n",
    "                en_relu1 = leaky_relu(en_conv1)\n",
    "                en_drop1 = dropout(en_relu1,self.keep_prob,self.is_train)\n",
    "                print('conv1 layer: ' + str(en_relu1.get_shape()))\n",
    "                en_conv2 =  conv2d(en_drop1, 4, 2, 64, 'conv2')\n",
    "                en_relu2 = leaky_relu(en_conv2)\n",
    "                en_drop2 = dropout(en_relu2,self.keep_prob,self.is_train)\n",
    "                print('conv2 layer: ' + str(en_relu2.get_shape()))\n",
    "                en_conv3 =  conv2d(en_drop2, 4, 2, 128, 'conv3')\n",
    "                en_relu3 = leaky_relu(en_conv3)\n",
    "                en_drop3 = dropout(en_relu3,self.keep_prob,self.is_train)\n",
    "                print('conv3 layer: ' + str(en_relu3.get_shape()))\n",
    "                x_unrol = tf.contrib.layers.flatten(en_drop3)\n",
    "                print('flatten data: ' + str(x_unrol.get_shape()))\n",
    "                full_1 = x_unrol\n",
    "                \n",
    "                #full_1 = tf.layers.dense(x_unrol, units=2048, activation=leaky_relu)\n",
    "                #print(\"full_1  : \",str(full_1.get_shape()))\n",
    "                \n",
    "                mean = tf.layers.dense(full_1, units=self.n_latent)\n",
    "                std_val = 0.5 * tf.layers.dense(full_1, units=self.n_latent)   \n",
    "                epsilon = tf.random_normal(tf.stack([tf.shape(full_1)[0], self.n_latent])) \n",
    "                z  = mean + tf.multiply(epsilon, tf.exp(std_val))\n",
    "                print(\"latent dimension mean: \",str(mean.get_shape()))\n",
    "                print(\"latent dimension std: \",str(std_val.get_shape()))\n",
    "                print(\"latent dimension z  : \",str(z.get_shape()))\n",
    "                \n",
    "                return z,mean,std_val\n",
    "    \n",
    "    def decoder(self,sampled_z):\n",
    "        dec_in_channels = 1\n",
    "        reshaped_dim = [-1, 8, 8, 128]\n",
    "        print(\"decoder z  : \",str(sampled_z.get_shape()))\n",
    "        with tf.variable_scope(\"decoder\", reuse=None):\n",
    "                dense_1 = tf.layers.dense(sampled_z, units=64, activation=leaky_relu)\n",
    "                print(\"x_1  : \",str(dense_1.get_shape()))\n",
    "                dense_2 = tf.layers.dense(dense_1, units=8*8*128, activation=leaky_relu)\n",
    "                print(\"x_2  : \",str(dense_2.get_shape()))\n",
    "                dense_3 = tf.reshape(dense_2, reshaped_dim)\n",
    "                print(\"input  : \",str(dense_3.get_shape()))\n",
    "                conv1 = tf.layers.conv2d_transpose(dense_3, filters=64, kernel_size=4, \n",
    "                                    strides=2, padding='same', activation=leaky_relu)\n",
    "                de_conv1 = dropout(conv1,self.keep_prob,self.is_train)\n",
    "                print(\"x_4  : \",str(conv1.get_shape()))\n",
    "                conv2 = tf.layers.conv2d_transpose(de_conv1, filters=32, kernel_size=4,\n",
    "                                    strides=2,padding='same', activation=leaky_relu)\n",
    "                de_conv2 = dropout(conv2,self.keep_prob,self.is_train)\n",
    "                print(\"x_5  : \",str(conv2.get_shape()))\n",
    "                img = tf.layers.conv2d_transpose(de_conv2, filters=3, kernel_size=4,\n",
    "                                    strides=2,padding='same', activation=tf.sigmoid)\n",
    "                print(\"img  : \",str(img.get_shape()))\n",
    "                return img\n",
    "            \n",
    "    def _build_model(self):\n",
    "        self.z,self.mean,self.std_val=self.encoder(self.X)\n",
    "        self.d_image = self.decoder(self.z)\n",
    "        unreshaped = tf.reshape(self.d_image, [-1, self.input_w*self.input_w*3])\n",
    "        print(\"unreshaped  : \",str(unreshaped.get_shape()))\n",
    "        #self.img_loss = tf.reduce_sum(tf.squared_difference(unreshaped, self.X_flat), 1)\n",
    "        self.recon_loss = -tf.reduce_sum( self.X_flat * tf.log(1e-10+unreshaped) +\n",
    "                                       (1-self.X_flat) * tf.log(1e-10+(1-unreshaped)),\n",
    "                                      axis = 1)\n",
    "        self.latent_loss = -0.5 * tf.reduce_sum(1.0 + 2.0 * self.std_val \n",
    "                                           - tf.square(self.mean) \n",
    "                                           - tf.exp(2.0 * self.std_val), axis = 1)\n",
    "        self.total_loss = tf.reduce_mean(self.recon_loss + self.latent_loss)\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.total_loss)\n",
    "        return\n",
    "    \n",
    "    def train(self,sess,X_train):\n",
    "        \n",
    "        tot_loss = []\n",
    "        tot_reconloss = []\n",
    "        tot_latentoss = []\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                feed_dict = {self.X : X_,self.is_train : True}\n",
    "                fetches = [self.train_op, self.total_loss, self.recon_loss, self.latent_loss]\n",
    "                \n",
    "                _, loss, recon_loss, latent_loss = sess.run(fetches, feed_dict=feed_dict)\n",
    "                tot_loss.append(loss)\n",
    "                tot_reconloss.append(np.mean(recon_loss))\n",
    "                tot_latentoss.append(np.mean(latent_loss))\n",
    "                \n",
    "            if epoch % 1 == 0:\n",
    "                 print('[Epoch {}] Loss: {}, Recon loss: {}, Latent loss: {}'.format(\n",
    "                            epoch, loss, np.mean(recon_loss), np.mean(latent_loss)))\n",
    "        \n",
    "        #plot losses\n",
    "        plt.subplot(212)\n",
    "        plt.title('Recon loss')\n",
    "        recon_hist_ = tot_reconloss[1::50]\n",
    "        plt.plot(recon_hist_, '-o')\n",
    "        plt.subplot(221)\n",
    "        plt.title('Latent loss')\n",
    "        latent_hist_ = tot_latentoss[1::50]\n",
    "        plt.plot(latent_hist_, '-o')\n",
    "        plt.subplot(222)\n",
    "        loss_hist = tot_loss[1::50]\n",
    "        plt.plot(loss_hist, '-o')\n",
    "        plt.show()\n",
    "        return loss_hist,recon_hist_,latent_hist_\n",
    "    \n",
    "    # generate an image from the decoder: z->x\n",
    "    def generate_sample(self,sess,z):\n",
    "        gen_image = sess.run(self.d_image, feed_dict={self.z: z,self.is_train : False})\n",
    "        return gen_image\n",
    "    \n",
    "    # reconstruct an input image using encoder-decoder: X->d_image\n",
    "    def reconstruct_sample(self,sess,X_input):\n",
    "        gen_image = sess.run(self.d_image, feed_dict={self.X : X_input,self.is_train : False})\n",
    "        return gen_image\n",
    "    \n",
    "    # transform input image into the latent representation: X->z\n",
    "    def transfor_input(self,sess,X_input):\n",
    "        fetches = [self.z,self.mean,self.std_val]\n",
    "        z_val,mean,std_val = sess.run(fetches,feed_dict={self.X : X_input,self.is_train : False})\n",
    "        return z_val,mean,std_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clear old computation graphs\n",
    "suffel_data=np.random.permutation(train_data.elements)\n",
    "X_train = train_data.feature_vec[suffel_data][:]\n",
    "Y_train = train_data.labels[suffel_data]\n",
    "for val in range(0,5):\n",
    "    suffel_data=np.random.permutation(train_data.elements)\n",
    "    X_temp = X_train[suffel_data][:]\n",
    "    Y_temp = Y_train[suffel_data]\n",
    "    X_train = X_temp\n",
    "    Y_train = Y_temp \n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "model = VAE()\n",
    "loss_hist,recon_hist_,latent_hist_=model.train(sess,X_train)\n",
    "print(\"------done------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.random.normal(size=[model.batch_size, model.n_latent])\n",
    "#z = np.ones((model.batch_size, model.n_latent))\n",
    "x_generated = model.generate_sample(sess,z)\n",
    "print(x_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_val=10\n",
    "print(z[viz_val])\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(x_generated[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_generated[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_generated[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()\n",
    "#fig, ax0 = plt.subplots(ncols=1,figsize=(16, 8))\n",
    "tt=None\n",
    "tt=(x_generated[viz_val,:,:,0]/2.0)+(x_generated[viz_val,:,:,1]*1.0)+(x_generated[viz_val,:,:,2]/3.0)\n",
    "plt.imshow(tt,cmap=plt.cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_reconstruct = model.reconstruct_sample(sess,X_train[0:model.batch_size][:])\n",
    "print(x_reconstruct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_val=5\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(X_train[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(X_train[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(X_train[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(x_reconstruct[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_reconstruct[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_reconstruct[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visulize latent space\n",
    "tot_eleval = int(num_training /  model.batch_size)\n",
    "z_val=np.empty((tot_eleval*model.batch_size,model.n_latent),dtype=float)\n",
    "print(tot_eleval,tot_eleval*model.batch_size,z_val.shape)\n",
    "for i in range(num_training // model.batch_size):\n",
    "    X_ = X_train[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa,_,_=model.transfor_input(sess,X_)\n",
    "    z_val[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "print(z_val.shape,len(z_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "pca = PCA(n_components=2,whiten=False)\n",
    "pca.fit(z_val)\n",
    "X=pca.transform(z_val)\n",
    "print(\"PCA variance ratio:\",pca.explained_variance_ratio_)\n",
    "plt.scatter(X[:,0],X[:,1],c=Y_train[0:len(z_val)])\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()\n",
    "\n",
    "tsne_model = TSNE(n_components=2,perplexity=50.0,learning_rate=200.0,init='random',verbose = 0)  #verbose 1 is good\n",
    "X_embedded = tsne_model.fit_transform(z_val)\n",
    "print(\"shape of transfored features\",X.shape,X_embedded.shape)\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)])\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()\n",
    "print(\"t-SNE Output: KL-Divergence:\",tsne_model.kl_divergence_,\"Steps: \",tsne_model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_val=25\n",
    "bsize = model.batch_size\n",
    "i_2H=np.argwhere(train_data.labels==0)\n",
    "nsample_2H=int(len(i_2H)/bsize)\n",
    "x_2Hreconstruct=np.empty((nsample_2H*bsize,64,64,3),dtype=float)\n",
    "viz_2H=i_2H[0:nsample_2H*bsize,0]\n",
    "input_2H=train_data.feature_vec[viz_2H][:]\n",
    "print(input_2H.shape)\n",
    "for i in range(nsample_2H):\n",
    "    X_ = input_2H[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa=model.reconstruct_sample(sess,X_)\n",
    "    x_2Hreconstruct[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(x_2Hreconstruct[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_2Hreconstruct[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_2Hreconstruct[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()\n",
    "#-----------------------1T-------------\n",
    "i_1T=np.argwhere(train_data.labels==1)\n",
    "nsample_1T=int(len(i_1T)/bsize)\n",
    "x_1Treconstruct=np.empty((nsample_1T*bsize,64,64,3),dtype=float)\n",
    "viz_1T=i_1T[0:nsample_1T*bsize,0]\n",
    "input_1T=train_data.feature_vec[viz_1T][:]\n",
    "for i in range(nsample_1T):\n",
    "    X_ = input_1T[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa=model.reconstruct_sample(sess,X_)\n",
    "    x_1Treconstruct[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(x_1Treconstruct[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_1Treconstruct[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_1Treconstruct[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()\n",
    "#----------------------defect---------------\n",
    "i_defect=np.argwhere(train_data.labels==2)\n",
    "nsample_d=int(len(i_defect)/bsize)\n",
    "x_dreconstruct=np.empty((nsample_d*bsize,64,64,3),dtype=float)\n",
    "viz_de=i_defect[0:nsample_d*bsize,0]\n",
    "input_de=train_data.feature_vec[viz_de][:]\n",
    "for i in range(nsample_d):\n",
    "    X_ = input_de[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa=model.reconstruct_sample(sess,X_)\n",
    "    x_dreconstruct[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(x_dreconstruct[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_dreconstruct[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_dreconstruct[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()\n",
    "print(\"total 2H:\",len(i_2H),nsample_2H)\n",
    "print(\"total 1T:\",len(i_1T),nsample_1T)\n",
    "print(\"total defect:\",len(i_defect),nsample_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zval_2H=np.empty((nsample_2H*bsize,model.n_latent),dtype=float)\n",
    "mu_2H=np.empty((nsample_2H*bsize,model.n_latent),dtype=float)\n",
    "\n",
    "zval_1T=np.empty((nsample_1T*bsize,model.n_latent),dtype=float)\n",
    "mu_1T=np.empty((nsample_1T*bsize,model.n_latent),dtype=float)\n",
    "\n",
    "zval_de=np.empty((nsample_d*bsize,model.n_latent),dtype=float)\n",
    "mu_de=np.empty((nsample_d*bsize,model.n_latent),dtype=float)\n",
    "\n",
    "for i in range(nsample_2H):\n",
    "    X_ = input_2H[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa,bb,_ = model.transfor_input(sess,X_)\n",
    "    zval_2H[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "    mu_2H[i * model.batch_size:(i + 1) * model.batch_size]=bb\n",
    "\n",
    "for i in range(nsample_1T):\n",
    "    X_ = input_1T[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa,bb,_ = model.transfor_input(sess,X_)\n",
    "    zval_1T[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "    mu_1T[i * model.batch_size:(i + 1) * model.batch_size]=bb\n",
    "\n",
    "for i in range(nsample_d):\n",
    "    X_ = input_de[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    aa,bb,_ = model.transfor_input(sess,X_)\n",
    "    zval_de[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "    mu_de[i * model.batch_size:(i + 1) * model.batch_size]=bb\n",
    "    \n",
    "mu_2H_avg=np.tile(np.average(mu_2H,axis=0),(64,1))\n",
    "mu_1T_avg=np.tile(np.average(mu_1T,axis=0),(64,1))\n",
    "mu_de_avg=np.tile(np.average(mu_de,axis=0),(64,1))\n",
    "print(\"shape Z:\",zval_2H.shape,zval_1T.shape,zval_de.shape)\n",
    "print(\"shape mu:\",mu_2H_avg.shape,mu_1T_avg.shape,mu_de_avg.shape)\n",
    "print(\"==done===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta=0\n",
    "viz_val=50\n",
    "diff_z=mu_2H_avg-mu_1T_avg\n",
    "\n",
    "#angle_t=np.arccos(np.dot(zval_2H[viz_val,:],zval_1T[viz_val,:]))\n",
    "\n",
    "#diff_z=mu_2H-mu_1T\n",
    "x_new = model.generate_sample(sess,delta*zval_2H[0*64:1*64][:]+(1-delta)*zval_1T[0*64:1*64][:])\n",
    "#x_new = model.generate_sample(sess,zval_2H[1*64:2*64][:]-delta*(mu_2H_avg-mu_1T_avg))\n",
    "#x_new = model.generate_sample(sess,zval_2H[0:64][:]-delta*(mu_2H[0:64][:]-mu_1T[0:64][:]))\n",
    "#x_new = model.generate_sample(sess,-0.3*zval_1T[0:64][:])\n",
    "\n",
    "#ax=(np.sin((1-delta)*angle_t))/np.sin(angle_t)\n",
    "#ay=(np.sin(delta*angle_t))/np.sin(angle_t)\n",
    "#print(\"ax and ay:\",ax,ay)\n",
    "#x_new = model.generate_sample(sess,ax*zval_2H[0:64][:]+ay*zval_1T[0:64][:])\n",
    "\n",
    "print(\"===done===\")\n",
    "print(diff_z[viz_val])\n",
    "fig, (ax0, ax1,ax2,ax3) = plt.subplots(ncols=4,figsize=(16, 8))\n",
    "ax0.imshow(x_new[viz_val,:,:,0],cmap=plt.cm.binary)\n",
    "ax1.imshow(x_new[viz_val,:,:,2],cmap=plt.cm.binary)\n",
    "ax2.imshow(x_new[viz_val,:,:,1],cmap=plt.cm.binary)\n",
    "tt=None\n",
    "tt=(x_new[viz_val,:,:,0]/2.0)+(x_new[viz_val,:,:,1]*1.0)+(x_new[viz_val,:,:,2]/2.0)\n",
    "ax3.imshow(tt,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Se1=x_new[viz_val,:,:,0]\n",
    "Se2=x_new[viz_val,:,:,2]\n",
    "Mo=x_new[viz_val,:,:,1]\n",
    "dim=Se1.shape[0]\n",
    "print(\"dimension of tensor:\",dim)\n",
    "atom_tensor=[Se1,Se2,Mo]\n",
    "zval=[-1.65,1.65,0.0]\n",
    "atype=['Se1','Se2','Mo']\n",
    "print(atom_tensor[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make neighborlist\n",
    "delta = 20.0/64.0\n",
    "thresh=0.1\n",
    "for ii in range(0,dim):\n",
    "    for jj in range(0,dim):\n",
    "        myid=dim*ii+jj\n",
    "        count=0\n",
    "        for kk in range(ii-1,ii+2):\n",
    "            for ll in range(jj-1,jj+2):\n",
    "                if kk==ii and ll==jj:\n",
    "                    continue\n",
    "                elif kk < 0 or kk >= dim or ll < 0 or ll >= dim:\n",
    "                    continue\n",
    "                else:\n",
    "                    count +=1\n",
    "                    child_id=dim*kk+ll\n",
    "                    nlist[myid][count]=child_id\n",
    "        nlist[myid][0]=count\n",
    "        #print(\"nlist\",nlist[myid,:])\n",
    "        #print(ii,jj,\":\",myid,\":\",i_val,j_val,nlist[myid][0],count) \n",
    "\n",
    "\n",
    "def dfs_search(node,atom_id,layer_tag,nlist,nflag):\n",
    "    nflag[node]=atom_id\n",
    "#    print(\"hi\",node,nlist[node,0:nlist[node,0]+1])\n",
    "    for ii in range(1,nlist[node][0]+1):\n",
    "        child_id = nlist[node][ii]\n",
    "        i_ch = child_id // dim\n",
    "        j_ch = child_id % dim\n",
    "        if layer_tag[i_ch][j_ch] > thresh and nflag[child_id] == 0 :\n",
    "            dfs_search(child_id,atom_id,layer_tag,nlist,nflag)\n",
    "    return\n",
    "\n",
    "def gen_coordinate(layer_tag,nlist,nflag):\n",
    "    count=0\n",
    "    for loc in range(0,dim*dim):\n",
    "        i_val=loc // dim\n",
    "        j_val=loc % dim\n",
    "        if layer_tag[i_val][j_val]> thresh and nflag[loc] == 0 :\n",
    "            count+=1\n",
    "            dfs_search(loc,count,layer_tag,nlist,nflag)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_num=-1\n",
    "total_atom=0\n",
    "for val in atom_tensor:\n",
    "    layer_num+=1\n",
    "    nlist=np.empty((dim*dim,9),dtype=int)\n",
    "    nflag=np.zeros(dim*dim,dtype=int)\n",
    "    count=gen_coordinate(val,nlist,nflag)\n",
    "    total_atom+=count\n",
    "    x_cor=np.zeros(count+1,dtype=float)\n",
    "    y_cor=np.zeros(count+1,dtype=float)\n",
    "    tot=np.zeros(count+1,dtype=float)\n",
    "    for ii in range(0,dim*dim):\n",
    "        if nflag[ii] != 0:\n",
    "            i_val=ii // dim\n",
    "            j_val=ii % dim\n",
    "            tot[nflag[ii]] += 1.0\n",
    "            x_cor[nflag[ii]] += i_val*delta\n",
    "            y_cor[nflag[ii]] += j_val*delta\n",
    "    for ii in range(1,count+1):\n",
    "        x_cor[ii]=x_cor[ii]/tot[ii]\n",
    "        y_cor[ii]=y_cor[ii]/tot[ii]\n",
    "        print(atype[layer_num],x_cor[ii],y_cor[ii],zval[layer_num])\n",
    "print(\"total_atom: \",total_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val='Spectral'\n",
    "plt.scatter(X[:,0],X[:,1],c=Y_train[0:len(z_val)],cmap=val)\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.savefig(\"pca.png\",dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)],cmap=val)\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.savefig(\"tsne.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_data2.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "pca = PCA(n_components=3,whiten=False)\n",
    "pca.fit(z_val)\n",
    "X=pca.transform(z_val)\n",
    "print(\"PCA variance ratio:\",pca.explained_variance_ratio_)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p=ax.scatter(X[:,0],X[:,2],X[:,1],c=Y_train[0:len(z_val)],cmap=val)\n",
    "fig.colorbar(p)\n",
    "fig.savefig(\"3dpca.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne_model = TSNE(n_components=2,perplexity=30.0,learning_rate=200.0,init='random',verbose = 0)  #verbose 1 is good\n",
    "X_embedded = tsne_model.fit_transform(z_val)\n",
    "print(\"shape of transfored features\",X.shape,X_embedded.shape)\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)])\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()\n",
    "print(\"t-SNE Output: KL-Divergence:\",tsne_model.kl_divergence_,\"Steps: \",tsne_model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)],cmap=val)\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.savefig(\"tsne.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arccos(np.dot(zval_2H[50,:],zval_1T[50,:]))*180/3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
