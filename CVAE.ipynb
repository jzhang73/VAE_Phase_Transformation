{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from loaddata import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data=readtraining_data(\"data/train_XX.p\",\"data/train_YY.npy\",\"data/train_pos.npy\")\n",
    "#train_data2=readtraining_data(\"inter_a_b/sur_XX.p\",\"inter_a_b/sur_YY.npy\",\"inter_a_b/sur_pos.npy\")\n",
    "#train_data=mergedata(train_data1,train_data2)\n",
    "train_data.print_info()\n",
    "output_class = 5\n",
    "print(train_data.labels.shape)\n",
    "#create training data\n",
    "stats,min_frac=count_stats(output_class,train_data.labels,train_data.elements)\n",
    "min_frac=0.99*min_frac\n",
    "train_data_1=select_data(train_data,min_frac,stats)\n",
    "print(\"====New Data====\")\n",
    "train_data=train_data_1\n",
    "train_data.print_info()\n",
    "num_training = train_data.elements\n",
    "count_stats(output_class,train_data.labels,train_data.elements)\n",
    "print(\"max value:\",np.max(train_data.feature_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defination of all the kernels\n",
    "def conv2d(input, kernel_size, stride, num_filter, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding = 'SAME') + b\n",
    "    \n",
    "def conv2d_transpose(input, kernel_size, stride, num_filter, name = 'conv2d_transpose'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "        output_shape = tf.stack([tf.shape(input)[0], tf.shape(input)[1] * 2, tf.shape(input)[2] * 2, num_filter])\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W, output_shape, stride_shape, padding = 'SAME') + b\n",
    "    \n",
    "def fc(input, num_output, name = 'fc'):\n",
    "    with tf.variable_scope(name):\n",
    "        num_input = input.get_shape()[1]\n",
    "        W = tf.get_variable('w', [num_input, num_output], tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [num_output], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input, W) + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "    \n",
    "def dropout(input,keep_prob,is_train):\n",
    "    return tf.layers.dropout(input,keep_prob,training=is_train)\n",
    "\n",
    "def batch_norm(input, is_training):\n",
    "    out = tf.contrib.layers.batch_norm(input, decay = 0.99, center = True, scale = True,\n",
    "                                       is_training = is_training, updates_collections = None)\n",
    "    return out\n",
    "\n",
    "def leaky_relu(input, alpha = 0.2):\n",
    "    return tf.maximum(alpha * input, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 100\n",
    "        self.input_w = 64\n",
    "        self.batch_size = 64\n",
    "        self.log_step = 50\n",
    "        self.learning_rate = 1e-3\n",
    "        self.n_latent = 10\n",
    "        self.is_train  = tf.placeholder(tf.bool)\n",
    "        self.keep_prob = 0.50\n",
    "        self.con_val = 5\n",
    "        self.X = tf.placeholder(tf.float32, [self.batch_size, self.input_w, self.input_w, 3])\n",
    "        self.X_flat = tf.reshape(self.X, shape=[-1, self.input_w * self.input_w * 3])\n",
    "        self.Y = tf.placeholder(tf.float32, [self.batch_size, self.con_val])\n",
    "        #self.Y = tf.one_hot(self.Ynorm, self.con_val)\n",
    "        print(str(self.X.get_shape()))\n",
    "        self._build_model()\n",
    "        #self.sess = tf.InteractiveSession()\n",
    "        #self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def encoder(self,input_x):\n",
    "         with tf.variable_scope(\"encoder\", reuse=None):\n",
    "                print('input: ' + str(input_x.get_shape()))\n",
    "                en_conv1 =  conv2d(input_x, 4, 2, 32, 'conv1')\n",
    "                en_relu1 = leaky_relu(en_conv1)\n",
    "                en_drop1 = dropout(en_relu1,self.keep_prob,self.is_train)\n",
    "                print('conv1 layer: ' + str(en_relu1.get_shape()))\n",
    "                en_conv2 =  conv2d(en_drop1, 4, 2, 64, 'conv2')\n",
    "                en_relu2 = leaky_relu(en_conv2)\n",
    "                en_drop2 = dropout(en_relu2,self.keep_prob,self.is_train)\n",
    "                print('conv2 layer: ' + str(en_relu2.get_shape()))\n",
    "                en_conv3 =  conv2d(en_drop2, 4, 2, 64, 'conv3')\n",
    "                en_relu3 = leaky_relu(en_conv3)\n",
    "                en_drop3 = dropout(en_relu3,self.keep_prob,self.is_train)\n",
    "                print('conv3 layer: ' + str(en_relu3.get_shape()))\n",
    "                x_unrol = tf.contrib.layers.flatten(en_drop3)\n",
    "                print('flatten data: ' + str(x_unrol.get_shape()))\n",
    "                full_1 = x_unrol\n",
    "                \n",
    "                #full_1 = tf.layers.dense(x_unrol, units=2048, activation=leaky_relu)\n",
    "                #print(\"full_1  : \",str(full_1.get_shape()))\n",
    "                \n",
    "                mean = tf.layers.dense(full_1, units=self.n_latent)\n",
    "                std_val = 0.5 * tf.layers.dense(full_1, units=self.n_latent)   \n",
    "                epsilon = tf.random_normal(tf.stack([tf.shape(full_1)[0], self.n_latent])) \n",
    "                z  = mean + tf.multiply(epsilon, tf.exp(std_val))\n",
    "                print(\"latent dimension mean: \",str(mean.get_shape()))\n",
    "                print(\"latent dimension std: \",str(std_val.get_shape()))\n",
    "                print(\"latent dimension z  : \",str(z.get_shape()))\n",
    "                \n",
    "                return z,mean,std_val\n",
    "    \n",
    "    def decoder(self,sampled_z):\n",
    "        dec_in_channels = 1\n",
    "        reshaped_dim = [-1, 8, 8, 64]\n",
    "        print(\"decoder z  : \",str(sampled_z.get_shape()))\n",
    "        with tf.variable_scope(\"decoder\", reuse=None):\n",
    "                dense_1 = tf.layers.dense(sampled_z, units=64, activation=leaky_relu)\n",
    "                print(\"x_1  : \",str(dense_1.get_shape()))\n",
    "                dense_2 = tf.layers.dense(dense_1, units=8*8*64, activation=leaky_relu)\n",
    "                print(\"x_2  : \",str(dense_2.get_shape()))\n",
    "                dense_3 = tf.reshape(dense_2, reshaped_dim)\n",
    "                print(\"input  : \",str(dense_3.get_shape()))\n",
    "                conv1 = tf.layers.conv2d_transpose(dense_3, filters=64, kernel_size=4, \n",
    "                                    strides=2, padding='same', activation=leaky_relu)\n",
    "                de_conv1 = dropout(conv1,self.keep_prob,self.is_train)\n",
    "                print(\"x_4  : \",str(conv1.get_shape()))\n",
    "                conv2 = tf.layers.conv2d_transpose(de_conv1, filters=32, kernel_size=4,\n",
    "                                    strides=2,padding='same', activation=leaky_relu)\n",
    "                de_conv2 = dropout(conv2,self.keep_prob,self.is_train)\n",
    "                print(\"x_5  : \",str(conv2.get_shape()))\n",
    "                img = tf.layers.conv2d_transpose(de_conv2, filters=3, kernel_size=4,\n",
    "                                    strides=2,padding='same', activation=tf.sigmoid)\n",
    "                print(\"img  : \",str(img.get_shape()))\n",
    "                return img\n",
    "            \n",
    "    def _build_model(self):\n",
    "        #build conditional input for encoder and decoder\n",
    "        _label = tf.reshape(self.Y, [-1, 1, 1, self.con_val])\n",
    "        _one = tf.ones([self.batch_size] + [64,64] + [self.con_val])\n",
    "        _label = _one * _label\n",
    "        \n",
    "        print(\"before concatinate  : \",str(_label.get_shape()),str(_one.get_shape()))\n",
    "        print(\"Y : \",str(self.Y.get_shape()))\n",
    "        print(\"X : \",str(self.X.get_shape()))\n",
    "        self.X_conc = tf.concat([self.X, _label], axis=3)\n",
    "        print(\"after concatinate  : \",str(self.X_conc.get_shape()))\n",
    "        \n",
    "        self.z,self.mean,self.std_val=self.encoder(self.X_conc)\n",
    "        print(\"z before: \",str(self.z.get_shape()))\n",
    "        self.z_conc = tf.concat([self.z, self.Y], axis=1)\n",
    "        print(\"z after: \",str(self.z_conc.get_shape()))\n",
    "        \n",
    "        self.d_image = self.decoder(self.z_conc)\n",
    "        unreshaped = tf.reshape(self.d_image, [-1, self.input_w*self.input_w*3])\n",
    "        print(\"unreshaped  : \",str(unreshaped.get_shape()))\n",
    "        #self.img_loss = tf.reduce_sum(tf.squared_difference(unreshaped, self.X_flat), 1)\n",
    "        \n",
    "        self.recon_loss = -tf.reduce_sum( self.X_flat * tf.log(1e-10+unreshaped) +\n",
    "                                       (1-self.X_flat) * tf.log(1e-10+(1-unreshaped)),\n",
    "                                      axis = 1)\n",
    "        self.latent_loss = -0.5 * tf.reduce_sum(1.0 + 2.0 * self.std_val \n",
    "                                           - tf.square(self.mean) \n",
    "                                           - tf.exp(2.0 * self.std_val), axis = 1)\n",
    "        self.total_loss = tf.reduce_mean(self.recon_loss + self.latent_loss)\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.total_loss)\n",
    "        return\n",
    "    \n",
    "    def train(self,sess,X_train,Y_train):\n",
    "        \n",
    "        tot_loss = []\n",
    "        tot_reconloss = []\n",
    "        tot_latentoss = []\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "#                print(\"one hot before:\",Y_.shape)\n",
    "                one_hot_encoding = np.zeros((self.batch_size,self.con_val))\n",
    "                one_hot_encoding[np.arange(self.batch_size),Y_] = 1\n",
    "                Y_ = np.reshape(one_hot_encoding, [-1, self.con_val])       \n",
    "#                print(\"one hot encoding:\",Y_.shape)\n",
    "                feed_dict = {self.X : X_,self.Y : Y_,self.is_train : True}\n",
    "                fetches = [self.train_op, self.total_loss, self.recon_loss, self.latent_loss]\n",
    "                \n",
    "                _, loss, recon_loss, latent_loss = sess.run(fetches, feed_dict=feed_dict)\n",
    "                tot_loss.append(loss)\n",
    "                tot_reconloss.append(np.mean(recon_loss))\n",
    "                tot_latentoss.append(np.mean(latent_loss))\n",
    "                \n",
    "            if epoch % 1 == 0:\n",
    "                 print('[Epoch {}] Loss: {}, Recon loss: {}, Latent loss: {}'.format(\n",
    "                            epoch, loss, np.mean(recon_loss), np.mean(latent_loss)))\n",
    "        \n",
    "        #plot losses\n",
    "        plt.subplot(212)\n",
    "        plt.title('Recon loss')\n",
    "        recon_hist_ = tot_reconloss[1::50]\n",
    "        plt.plot(recon_hist_, '-o')\n",
    "        plt.subplot(221)\n",
    "        plt.title('Latent loss')\n",
    "        latent_hist_ = tot_latentoss[1::50]\n",
    "        plt.plot(latent_hist_, '-o')\n",
    "        plt.subplot(222)\n",
    "        loss_hist = tot_loss[1::50]\n",
    "        plt.plot(loss_hist, '-o')\n",
    "        plt.show()\n",
    "        return loss_hist,recon_hist_,latent_hist_\n",
    "\n",
    "    # generate an image from the decoder: z->x\n",
    "    def generate_sample(self,sess,z):\n",
    "        gen_image = sess.run(self.d_image, feed_dict={self.z_conc: z,self.is_train : False})\n",
    "        return gen_image\n",
    "    \n",
    "    # reconstruct an input image using encoder-decoder: X->d_image\n",
    "    def reconstruct_sample(self,sess,X_input,Y_input):\n",
    "        one_hot_encoding = np.zeros((self.batch_size,self.con_val))\n",
    "        one_hot_encoding[np.arange(self.batch_size),Y_input] = 1\n",
    "        Y_input = np.reshape(one_hot_encoding, [-1, self.con_val]) \n",
    "        gen_image = sess.run(self.d_image, feed_dict={self.X : X_input,self.Y : Y_input,self.is_train : False})\n",
    "        return gen_image\n",
    "    \n",
    "    # transform input image into the latent representation: X->z\n",
    "    def transfor_input(self,sess,X_input):\n",
    "        fetches = [self.z,self.mean,self.std_val]\n",
    "        z_val,mean,std_val = sess.run(fetches,feed_dict={self.X_conc : X_input,self.is_train : False})\n",
    "        return z_val,mean,std_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear old computation graphs\n",
    "suffel_data=np.random.permutation(train_data.elements)\n",
    "X_train = train_data.feature_vec[suffel_data][:]\n",
    "Y_train = train_data.labels[suffel_data]\n",
    "for val in range(0,3):\n",
    "    suffel_data=np.random.permutation(train_data.elements)\n",
    "    X_temp = X_train[suffel_data][:]\n",
    "    Y_temp = Y_train[suffel_data]\n",
    "    X_train = X_temp\n",
    "    Y_train = Y_temp \n",
    "Y_train=Y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "model = VAE()\n",
    "model.train(sess,X_train,Y_train)\n",
    "print(\"------done------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.random.normal(size=[model.batch_size, model.n_latent])\n",
    "cval=np.empty(model.batch_size,dtype='int')\n",
    "cval.fill(2)\n",
    "one_hot_encoding = np.zeros((model.batch_size,model.con_val))\n",
    "one_hot_encoding[np.arange(model.batch_size),cval] = 1\n",
    "cval = np.reshape(one_hot_encoding, [-1, model.con_val])\n",
    "print(z.shape,cval.shape)\n",
    "z = np.concatenate([z, cval], axis=1)\n",
    "print(z.shape)\n",
    "x_generated = model.generate_sample(sess,z)\n",
    "print(x_generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_val=8\n",
    "print(z.shape,z[viz_val])\n",
    "fig, (ax0, ax1,ax2,ax3) = plt.subplots(ncols=4,figsize=(16, 8))\n",
    "ax0.imshow(x_generated[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_generated[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_generated[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "tt=None\n",
    "tt=(x_generated[viz_val,:,:,0]/2.0)+(x_generated[viz_val,:,:,1]*1.0)+(x_generated[viz_val,:,:,2]/3.0)\n",
    "ax3.imshow(tt,cmap=plt.cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_reconstruct = model.reconstruct_sample(sess,X_train[0:model.batch_size][:],Y_train[0:model.batch_size])\n",
    "print(x_reconstruct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_val=5\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(X_train[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(X_train[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(X_train[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()\n",
    "fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(16, 8))\n",
    "ax0.imshow(x_reconstruct[viz_val,:,:,0],cmap=plt.cm.cool)\n",
    "ax1.imshow(x_reconstruct[viz_val,:,:,1],cmap=plt.cm.cool)\n",
    "ax2.imshow(x_reconstruct[viz_val,:,:,2],cmap=plt.cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visulize latent space\n",
    "tot_eleval = int(num_training /  model.batch_size)\n",
    "z_val=np.empty((tot_eleval*model.batch_size,model.n_latent),dtype=float)\n",
    "print(tot_eleval,tot_eleval*model.batch_size,z_val.shape)\n",
    "for i in range(num_training // model.batch_size):\n",
    "    X_ = X_train[i * model.batch_size:(i + 1) * model.batch_size][:]\n",
    "    Y_ = Y_train[i * model.batch_size:(i + 1) * model.batch_size]\n",
    "    Y_temp = np.zeros((model.batch_size,model.con_val))\n",
    "    Y_temp[np.arange(model.batch_size),Y_] = 1\n",
    "#    print(Y_temp.shape)\n",
    "    Y_ = np.reshape(Y_temp, [-1, model.con_val])\n",
    "#    print(Y_.shape)\n",
    "    _label = np.reshape(Y_, [-1, 1, 1, model.con_val])\n",
    "#    print(_label.shape)\n",
    "    _one = np.ones([model.batch_size] + [64,64] + [model.con_val])\n",
    "    _label = _one * _label\n",
    "    Xt = np.concatenate([X_, _label], axis=3)\n",
    "    aa,_,_=model.transfor_input(sess,Xt)\n",
    "    z_val[i * model.batch_size:(i + 1) * model.batch_size]=aa\n",
    "print(z_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "pca = PCA(n_components=2,whiten=False)\n",
    "pca.fit(z_val)\n",
    "X=pca.transform(z_val)\n",
    "print(\"PCA variance ratio:\",pca.explained_variance_ratio_)\n",
    "plt.scatter(X[:,0],X[:,1],c=Y_train[0:len(z_val)])\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()\n",
    "\n",
    "tsne_model = TSNE(n_components=2,perplexity=50.0,learning_rate=200.0,init='random',verbose = 0)  #verbose 1 is good\n",
    "X_embedded = tsne_model.fit_transform(z_val)\n",
    "print(\"shape of transfored features\",X.shape,X_embedded.shape)\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)])\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()\n",
    "print(\"t-SNE Output: KL-Divergence:\",tsne_model.kl_divergence_,\"Steps: \",tsne_model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Se1=x_generated[viz_val,:,:,0]\n",
    "Se2=x_generated[viz_val,:,:,2]\n",
    "Mo=x_generated[viz_val,:,:,1]\n",
    "dim=Se1.shape[0]\n",
    "print(\"dimension of tensor:\",dim)\n",
    "atom_tensor=[Se1,Se2,Mo]\n",
    "zval=[-1.65,1.65,0.0]\n",
    "atype=['Se1','Se2','Mo']\n",
    "print(atom_tensor[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make neighborlist\n",
    "delta = 20.0/64.0\n",
    "thresh=0.1\n",
    "for ii in range(0,dim):\n",
    "    for jj in range(0,dim):\n",
    "        myid=dim*ii+jj\n",
    "        count=0\n",
    "        for kk in range(ii-1,ii+2):\n",
    "            for ll in range(jj-1,jj+2):\n",
    "                if kk==ii and ll==jj:\n",
    "                    continue\n",
    "                elif kk < 0 or kk >= dim or ll < 0 or ll >= dim:\n",
    "                    continue\n",
    "                else:\n",
    "                    count +=1\n",
    "                    child_id=dim*kk+ll\n",
    "                    nlist[myid][count]=child_id\n",
    "        nlist[myid][0]=count\n",
    "        #print(\"nlist\",nlist[myid,:])\n",
    "        #print(ii,jj,\":\",myid,\":\",i_val,j_val,nlist[myid][0],count) \n",
    "\n",
    "\n",
    "def dfs_search(node,atom_id,layer_tag,nlist,nflag):\n",
    "    nflag[node]=atom_id\n",
    "#    print(\"hi\",node,nlist[node,0:nlist[node,0]+1])\n",
    "    for ii in range(1,nlist[node][0]+1):\n",
    "        child_id = nlist[node][ii]\n",
    "        i_ch = child_id // dim\n",
    "        j_ch = child_id % dim\n",
    "        if layer_tag[i_ch][j_ch] > thresh and nflag[child_id] == 0 :\n",
    "            dfs_search(child_id,atom_id,layer_tag,nlist,nflag)\n",
    "    return\n",
    "\n",
    "def gen_coordinate(layer_tag,nlist,nflag):\n",
    "    count=0\n",
    "    for loc in range(0,dim*dim):\n",
    "        i_val=loc // dim\n",
    "        j_val=loc % dim\n",
    "        if layer_tag[i_val][j_val]> thresh and nflag[loc] == 0 :\n",
    "            count+=1\n",
    "            dfs_search(loc,count,layer_tag,nlist,nflag)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_num=-1\n",
    "total_atom=0\n",
    "for val in atom_tensor:\n",
    "    layer_num+=1\n",
    "    nlist=np.empty((dim*dim,9),dtype=int)\n",
    "    nflag=np.zeros(dim*dim,dtype=int)\n",
    "    count=gen_coordinate(val,nlist,nflag)\n",
    "    total_atom+=count\n",
    "    x_cor=np.zeros(count+1,dtype=float)\n",
    "    y_cor=np.zeros(count+1,dtype=float)\n",
    "    tot=np.zeros(count+1,dtype=float)\n",
    "    for ii in range(0,dim*dim):\n",
    "        if nflag[ii] != 0:\n",
    "            i_val=ii // dim\n",
    "            j_val=ii % dim\n",
    "            tot[nflag[ii]] += 1.0\n",
    "            x_cor[nflag[ii]] += i_val*delta\n",
    "            y_cor[nflag[ii]] += j_val*delta\n",
    "    for ii in range(1,count+1):\n",
    "        x_cor[ii]=x_cor[ii]/tot[ii]\n",
    "        y_cor[ii]=y_cor[ii]/tot[ii]\n",
    "        print(atype[layer_num],x_cor[ii],y_cor[ii],zval[layer_num])\n",
    "print(\"total_atom: \",total_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val='Spectral'\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)],cmap=val)\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne_model = TSNE(n_components=2,perplexity=30.0,learning_rate=200.0,init='random',verbose = 0)  #verbose 1 is good\n",
    "X_embedded = tsne_model.fit_transform(z_val)\n",
    "print(\"shape of transfored features\",X.shape,X_embedded.shape)\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)])\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()\n",
    "print(\"t-SNE Output: KL-Divergence:\",tsne_model.kl_divergence_,\"Steps: \",tsne_model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val='Spectral'\n",
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=Y_train[0:len(z_val)],cmap=val)\n",
    "plt.colorbar(ticks=np.arange(np.min(Y_train),np.max(Y_train)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
